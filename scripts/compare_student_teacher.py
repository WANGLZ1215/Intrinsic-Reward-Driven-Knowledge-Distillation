#!/usr/bin/env python3
"""
Compare student/teacher results on GSM8K, calculate:
- Individual accuracy (based on numerical/text comparison using extract_answer_unified)
- Approximate distillation metrics (based on top-k distribution at prompt): KL, reverse KL, JS, cosine similarity

Input: Two JSONL files generated by export_gsm8k_answers.py (student / teacher)
"""

import argparse
import json
import logging
from pathlib import Path
from typing import Dict, List, Tuple
import math


def setup_logging(level: str = "INFO") -> None:
    logging.basicConfig(level=getattr(logging, level.upper()),
                        format='%(asctime)s - %(levelname)s - %(message)s')


def load_jsonl(path: str) -> Dict[int, Dict]:
    data: Dict[int, Dict] = {}
    with open(path, 'r', encoding='utf-8') as f:
        for line in f:
            if not line.strip():
                continue
            obj = json.loads(line)
            data[int(obj["index"])]=obj
    return data


def accuracy(data: Dict[int, Dict]) -> float:
    total = len(data)
    correct = 0
    for v in data.values():
        gt_num = v.get("ground_truth_num")
        ans_num = v.get("answer_num")
        if isinstance(gt_num, (int,float)) and isinstance(ans_num,(int,float)):
            # Numerical comparison (with tolerance)
            tol = 1e-6
            if abs(float(ans_num) - float(gt_num)) < tol:
                correct += 1
        else:
            # Text fallback
            gt_text = str(v.get("ground_truth_text",""))
            ans_text = str(v.get("answer_text",""))
            if gt_text and ans_text and gt_text.strip().lower()==ans_text.strip().lower():
                correct += 1
    return correct/total if total>0 else 0.0


def sparse_vec(top_ids: List[int], top_probs: List[float]) -> Dict[int, float]:
    return {int(i): float(p) for i,p in zip(top_ids, top_probs)}


def kl_divergence(p: Dict[int,float], q: Dict[int,float], eps: float=1e-12) -> float:
    # KL(P||Q)
    keys = set(p.keys()) | set(q.keys())
    s = 0.0
    for k in keys:
        pk = max(eps, p.get(k, 0.0))
        qk = max(eps, q.get(k, 0.0))
        s += pk * math.log(pk / qk)
    return float(s)


def js_divergence(p: Dict[int,float], q: Dict[int,float], eps: float=1e-12) -> float:
    m: Dict[int,float] = {}
    keys = set(p.keys()) | set(q.keys())
    for k in keys:
        m[k] = 0.5*(p.get(k,0.0)+q.get(k,0.0))
    return 0.5*kl_divergence(p,m,eps) + 0.5*kl_divergence(q,m,eps)


def cosine_similarity(p: Dict[int,float], q: Dict[int,float], eps: float=1e-12) -> float:
    keys = set(p.keys()) | set(q.keys())
    dot = sum(p.get(k,0.0)*q.get(k,0.0) for k in keys)
    np = math.sqrt(sum((v*v) for v in p.values()))
    nq = math.sqrt(sum((v*v) for v in q.values()))
    if np<eps or nq<eps:
        return 0.0
    return float(dot/(np*nq))


def main():
    parser = argparse.ArgumentParser(description="Compare student/teacher GSM8K results and calculate distillation metrics")
    parser.add_argument("--student_jsonl", required=True, help="Student JSONL path")
    parser.add_argument("--teacher_jsonl", required=True, help="Teacher JSONL path")
    parser.add_argument("--log_level", default="INFO")
    args = parser.parse_args()

    setup_logging(args.log_level)

    stu = load_jsonl(args.student_jsonl)
    tea = load_jsonl(args.teacher_jsonl)

    common_idx = sorted(set(stu.keys()) & set(tea.keys()))
    logging.info(f"Sample alignment: {len(common_idx)} entries")
    
    # Filter out samples with errors (for accuracy calculation)
    valid_idx = [i for i in common_idx 
                 if not stu[i].get("error") and not tea[i].get("error")]
    
    logging.info(f"Valid samples (no errors): {len(valid_idx)}/{len(common_idx)}")

    acc_stu = accuracy({i:stu[i] for i in valid_idx}) if valid_idx else 0.0
    acc_tea = accuracy({i:tea[i] for i in valid_idx}) if valid_idx else 0.0
    logging.info(f"Student accuracy: {acc_stu:.4f}")
    logging.info(f"Teacher accuracy: {acc_tea:.4f}")

    # Distillation metrics (based on top-k distribution at prompt, only calculate for valid samples)
    kls, r_kls, jss, coss = [], [], [], []
    for i in valid_idx:
        p = sparse_vec(stu[i].get("top_ids",[]), stu[i].get("top_probs",[]))
        q = sparse_vec(tea[i].get("top_ids",[]), tea[i].get("top_probs",[]))
        if not p or not q:
            continue
        kls.append(kl_divergence(p,q))
        r_kls.append(kl_divergence(q,p))
        jss.append(js_divergence(p,q))
        coss.append(cosine_similarity(p,q))

    def avg(x: List[float]) -> float:
        return float(sum(x)/len(x)) if x else float('nan')

    logging.info("Approximate distillation metrics (top-k distribution at prompt)")
    logging.info(f"  KL(student||teacher): {avg(kls):.6f} (n={len(kls)})")
    logging.info(f"  KL(teacher||student): {avg(r_kls):.6f}")
    logging.info(f"  JS: {avg(jss):.6f}")
    logging.info(f"  Cosine: {avg(coss):.6f}")


if __name__ == "__main__":
    main()


